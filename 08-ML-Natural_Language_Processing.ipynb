{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет для классификации (бинарная) текстов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** https://www.kaggle.com/areeves87/rscience-popular-comment-removal **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BODY</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Always be wary of news articles that cite unpu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The problem I have with this is that the artic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is indicative of a typical power law, and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This doesn't make sense. Chess obviously trans...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. I dispute that gene engineering is burdenso...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Very misleading headline.  Using CRISPR, it wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>At least we are getting pretty smart at detect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Democracy is the worst kind of government, exc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Journal Reference:- [cell.com] (http://dx.doi....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There has been some interesting research on ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                BODY  REMOVED\n",
       "0  Always be wary of news articles that cite unpu...        0\n",
       "1  The problem I have with this is that the artic...        0\n",
       "2  This is indicative of a typical power law, and...        0\n",
       "3  This doesn't make sense. Chess obviously trans...        0\n",
       "4  1. I dispute that gene engineering is burdenso...        0\n",
       "5  Very misleading headline.  Using CRISPR, it wa...        0\n",
       "6  At least we are getting pretty smart at detect...        1\n",
       "7  Democracy is the worst kind of government, exc...        0\n",
       "8  Journal Reference:- [cell.com] (http://dx.doi....        0\n",
       "9  There has been some interesting research on ca...        0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('reddit_train.csv', encoding = 'latin-1')\n",
    "df_train.drop(columns = ['Unnamed: 0', 'X'], inplace = True)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REMOVED</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BODY\n",
       "REMOVED       \n",
       "0        14479\n",
       "1         6857"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"REMOVED\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BODY</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is there any veracity to the claims that peopl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to the 1980's, Head of NASA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hold on while I stroke my ego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wonder if this is associated with majority o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So, just like everyone, everywhere, then?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                BODY  REMOVED\n",
       "0  Is there any veracity to the claims that peopl...        0\n",
       "1               Welcome to the 1980's, Head of NASA         1\n",
       "2                      Hold on while I stroke my ego        1\n",
       "3  I wonder if this is associated with majority o...        0\n",
       "4          So, just like everyone, everywhere, then?        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('reddit_test.csv', encoding = 'latin-1')\n",
    "df_test.drop(columns = ['Unnamed: 0', 'X'], inplace = True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BODY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REMOVED</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BODY\n",
       "REMOVED      \n",
       "0        4812\n",
       "1        2299"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby(\"REMOVED\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводим в цикле целиком текст первых нескольких записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______\n",
      "      \n",
      "[\"Always be wary of news articles that cite unpublished studies. Even if they are eventually published as claimed, it's not the responsible way to report on science.\\r\\n\\r\\nIt could be an absolutely shit study, but once the claims are made in public you can't unring the bell. At least if the study is reported on *when* it is published, one can challenge it at the same time. \"]\n",
      "______\n",
      "      \n",
      "['The problem I have with this is that the article appears to credit the plain packets with the decline in smoking. \\r\\n\\r\\n\"Between 2010 and 2013, the proportion of daily smokers in Australia dropped from 15.1 to 12.8 per cent - a record decline.\" In other words, a drop of 2.3 percent (15.1 - 12.8). \\r\\n\\r\\nYet in the United States - which does *not* have plain packaging - the rate dropped from 19.3 (in 2010) to 17.8 (in 2013). That\\'s 1.5 percent (19.3 - 17.8). Granted, that\\'s not as much as Australia\\'s decline but it indicates that you cannot credit Australia\\'s entire decline to the plain packaging since declines happened in places without plain packaging.\\r\\n\\r\\n']\n",
      "______\n",
      "      \n",
      "[\"This is indicative of a typical power law, and is found in any number of areas.  I'm actually a bit surprised that it is only half.\"]\n",
      "______\n",
      "      \n",
      "['This doesn\\'t make sense. Chess obviously translates into other disciplines. The strategies present in chess translate to strategies faced in every conceivable mode of existence. Learning how to sacrifice a piece can translate into learning how to lose a battle to win a war. Or how to distract your opponent with a juicy tidbit only to go after your real prize.\\r\\n\\r\\nI love chess and when I started training Brazilian Jiu Jitsu and Judo the comparison was immedietky recognizable. Feign weakness present a target to distract, don\\'t push back against resistance, but use it to your advantage encouraging your opponent to overextend or overcommit.\\r\\n\\r\\nThis has much more far reaching applicability beyond chess or war or even competitive sports or combat sports. It holds up in politics and heirarchal relationships of every kind.\\r\\n\\r\\nIt holds water in a negotiation or an argument, for example. Or when asking for a raise.\\r\\n\\r\\nThe applicability of chess is to understand the concept, philosophy, and psychology behind it and the benefits are far reaching.\\r\\n\\r\\nSimilarly you can take disciplines in the arts and compare them to other situations.\\r\\n\\r\\nHow often did war lords during China\\'s warring states period study the discipline and gentleness of the calligrapher just to have an epiphany about a certain strategy and so on. Gentle strokes, don\\'t press too hard...etc.\\r\\n\\r\\nWill playing chess make you a better guitar player? No, but understanding the structure and composition  of a universally pleasant melody and the methodology of a chess match are interchangeable and useful as a life philaophy applicable to every conceivable aspect of existence. \\r\\n\\r\\nAt any given moment in any other discipline I practice, I can draw comparisons and lessons from each that flow into the other.\\r\\n\\r\\nIf I am learning an instrument I can think to myself, \"Let\\'s approach this like a chess match....\" Or if I am playing chess I can say, \"Let me approach this like a musical composition...building by layers.\" \\r\\n\\r\\nEDIT: On phone. Forgive the typos.']\n",
      "______\n",
      "      \n",
      "[\"1. I dispute that gene engineering is burdensome especially in the era of CRISPR technology- this is only going to get better, cheaper, and more effective. Like the field of computing.\\r\\n\\r\\n2. Looking at CARs as an example, there was a reported case of a single T cell expanding enough to drive the patient to complete remission. So it's possible for a small population of T cells to drive defense.\\r\\n\\r\\n3. Any cells (like DCs or Macs etc) hiding the virus would still be vulnerable to native immune attack and destruction as now the hosts immune system is restore to better viral surveillance.  \\r\\n\\r\\n4. To prevent further mutation or expansion of some variant resistant to this new immunotherapy, some form of HAART (which then could also be lessened) could still be employed thereby hitting the virus with two-different forms of treatment: cellular + small-molecule.\\r\\n\\r\\n5. While you are gene engineering you could remove HIV T cell co-receptors CCR5 and/ or CXCR4.\\r\\n\\r\\nAgain, I think CARs demonstrate the feasibility of this approach. And we can predict some behavior of long-lived virus-specific T c lol clones in the body.\\r\\n\\r\\nIt's too early to tell, what certainly a plausible endeavor.\"]\n",
      "______\n",
      "      \n",
      "['Very misleading headline.  Using CRISPR, it was possible to eliminate the HIV-1 virus from : 1.  Single cells cultured from animals and 2. Some cells within several organs in live animals.  The headline suggests that the virus was \"eliminated from the animal\" -- that is that it affected every infected cell.  That is what would be required,(slightly simplified) for a cure.  This is the problem with most genetic approaches -- the difficulty of accessing and treating enough cells.  It is easier trying to treat, for instance, a genetic disease in which a subpopulation of the cells can be altered to produce or to eliminate  a sufficient amount of product .  But to correct every infected cell... that\\'s going to be a tough one. ']\n",
      "______\n",
      "      \n",
      "['At least we are getting pretty smart at detecting how stupid we are.']\n",
      "______\n",
      "      \n",
      "[\"Democracy is the worst kind of government, except for all of the other forms we've tried.\"]\n",
      "______\n",
      "      \n",
      "['Journal Reference:- [cell.com] (http://dx.doi.org/10.1016/j.cell.2016.12.014)\\r\\n']\n",
      "______\n",
      "      \n",
      "['There has been some interesting research on cat personalities by colouring. We have a tortoiseshell cat, and apparently \"tortitude\" is a real phenomenon. ']\n",
      "______\n",
      "      \n",
      "[\"Everyone is trying to brute force their way through fighting climate change. Why don't we make climate change a positive side effect to air quality in general? People will deny that humans played a substantial role in climate change but nobody would argue for dirtier air. \"]\n",
      "______\n",
      "      \n",
      "['Actually, I was very afraid of heights. One day I decided to set my SteamVR environment as an image above clouds. It was quite OK because the platform was opaque and big enough for me not to really see the floor beneath me.\\r\\n\\r\\nEvery day I gradually decreased the opacity of the platform and, despite still being a bit shaky, I can look down and not collapse in fear.\\r\\n\\r\\nI live away from my home country now. After this VR experience, the next flight I booked home had, for the first time, a window seat. I have to say I now enjoy the experience of plane travel (except for the whole \"treated like cattle before entering the plane\" bit).']\n",
      "______\n",
      "      \n",
      "['What are the health risks compared to real meat and milk?']\n",
      "______\n",
      "      \n",
      "['It\\'s also a godsend for people with panic attacks. I\\'ve had a chance to try it and the fact of just \"relaxing\" without getting stoned was marvelous. ']\n",
      "______\n",
      "      \n",
      "[\"Surprised that at the time of this comment nobody has made a reference to the 'Corrupted Blood incident' in World of Warcraft. \"]\n",
      "______\n",
      "      \n",
      "['this can likely also be achieved by teaching logic classes and requiring and funding the sciences in highschool with a requirement for passing these classes being the students showing the ability to apply the scientific method to experiments.']\n",
      "______\n",
      "      \n",
      "['Wow, this is really interesting. I just assumed that all of the Canaanites had been wiped out at this point. I wonder what happened to the Assyrians. ']\n",
      "______\n",
      "      \n",
      "['This does not surprise me in the least in light of recent developments in understanding gene expression. Imagine the possibility of generations long impact unleashed on residents of Iraq, Libya, Yemen, Afghanistan, Viet Nam, Syria, etc.']\n",
      "______\n",
      "      \n",
      "['Although the research is in Cell (one of the most prestigious journals), this sounds more like a \"methods\" paper describing an exciting new model rather than a major mechanistic discovery. Development of a great model can be really important  (hence Cell) and may be used in a lot of important future studies, but mitochindrial dysfunction during aging is a well studied phenomenon.\\r\\n\\r\\nWhat\\'s interesting is that, paradoxically, slight impairment of mitochondria early in life can extend life span is some animal models (worms, flies etc.). ']\n",
      "______\n",
      "      \n",
      "['\"...intermittent fasting...increase lifespan...\" \\r\\n\\r\\nGuess it\\'s time to stop! ']\n",
      "______\n",
      "      \n",
      "[\"There's a connection between the mind and body. If you keep all parts maintained they'll work better together, or at least from my experience. \"]\n"
     ]
    }
   ],
   "source": [
    "for i in df_train.BODY[:21]:\n",
    "    print(\"______\")\n",
    "    print(\"      \")\n",
    "    print([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Находим малоинформативные повторяющиеся участки в текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\", \"at\")\n",
    "    \n",
    "    df[text_field] = df[text_field].str.replace(r\"(http|https)://[^\\s]*\", \" httpaddr \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"\\b[^\\s]+@[^\\s]+[.][^\\s]+\\b\", \" emailaddr \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"\\b[\\d.]+\\b\", \" number \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[$]\", \" dollar \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[!]\", \" exclammark \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[?]\", \" questmark \")\n",
    "    \n",
    "    # Remove all other punctuation (replace with white space)\n",
    "    df[text_field] = df[text_field].str.replace(r\"([^\\w\\s]+)|([_-]+)\", \" \")\n",
    "    \n",
    "    # Remove all other punctuation (replace with white space)\n",
    "    df[text_field] = df[text_field].str.replace(r\"\\n\", \" newline \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"\\n\\n\", \" blankline \")\n",
    "    \n",
    "    # Make all white space a single space\n",
    "    df[text_field] = df[text_field].str.replace(r\"\\s+\", \" \")\n",
    "\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    " \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = clean_text(df_train, \"BODY\")\n",
    "df_test = clean_text(df_test, \"BODY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BODY</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>always be wary of news articles that cite unpu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the problem i have with this is that the artic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is indicative of a typical power law and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this doesn t make sense chess obviously transl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number i dispute that gene engineering is bur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                BODY  REMOVED\n",
       "0  always be wary of news articles that cite unpu...        0\n",
       "1  the problem i have with this is that the artic...        0\n",
       "2  this is indicative of a typical power law and ...        0\n",
       "3  this doesn t make sense chess obviously transl...        0\n",
       "4   number i dispute that gene engineering is bur...        0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BODY</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is there any veracity to the claims that peopl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to the number s head of nasa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hold on while i stroke my ego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i wonder if this is associated with majority o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>so just like everyone everywhere then questmark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                BODY  REMOVED\n",
       "0  is there any veracity to the claims that peopl...        0\n",
       "1              welcome to the number s head of nasa         1\n",
       "2                      hold on while i stroke my ego        1\n",
       "3  i wonder if this is associated with majority o...        0\n",
       "4   so just like everyone everywhere then questmark         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проходимся по текстам стеммером — приводим все слова к нормальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# def stem(word):\n",
    "#     regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "#     stem, suffix = re.findall(regexp, word)[0]\n",
    "#     return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "\n",
    "stemobject = Stemmer.Stemmer('english')\n",
    "\n",
    "def stemmer(x):\n",
    "    stem_function = stemobject.stemWord\n",
    "    out = [stem_function(word) for word in x.split(' ')]\n",
    "    return ' '.join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём матрицу TfIdf с помощью TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "en_stopwords = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "#     tokenizer=nltk.word_tokenize,\n",
    "#     preprocessor = stemmer,\n",
    "#     stop_words=\"english\",\n",
    "#     stop_words=en_stopwords\n",
    ")\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = tfidf.fit_transform(df_train['BODY'])\n",
    "y_train = df_train['REMOVED']\n",
    "X_test = tfidf.transform(df_test['BODY']) \n",
    "y_test = df_test['REMOVED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применяем Logistic Regression к получившейся матрице tfidf, проводим классификацию (с помощью кросс-валидации), выводим получившиеся метрики качества (accuracy, classification_report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegressionCV()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753339895935874"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.83      4812\n",
      "          1       0.66      0.49      0.56      2299\n",
      "\n",
      "avg / total       0.74      0.75      0.74      7111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4235,  577],\n",
       "       [1177, 1122]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4235, 577, 1177, 1122)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, clf.predict(X_test)).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация и подбор наилучших гиперпатаметров и способа предобработки текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(stop_words=\"english\"), \n",
    "                         LogisticRegression())\n",
    "params = {'logisticregression__C': (0.1, 1, 10),\n",
    "          \"tfidfvectorizer__ngram_range\": ((1, 1), (1, 2)),\n",
    "          \"tfidfvectorizer__max_df\": (0.5, 0.75, 1.0),\n",
    "          \"tfidfvectorizer__min_df\":(1, 5, 10, 20, 50),\n",
    "          \"tfidfvectorizer__max_features\":(None, 5000, 10000, 50000)}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(stop_words=\"english\"), \n",
    "                         LogisticRegression())\n",
    "params = {'logisticregression__C': (0.1, 1, 10),\n",
    "          \"tfidfvectorizer__preprocessor\":(None, stemmer),        \n",
    "          \"tfidfvectorizer__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "          \"tfidfvectorizer__max_df\": (0.5, 0.75, 1.0),\n",
    "          \"tfidfvectorizer__min_df\":(1, 5, 10, 20, 50),\n",
    "          \"tfidfvectorizer__max_features\":(None, 5000, 10000, 50000)}\n",
    "\n",
    "grid2 = GridSearchCV(pipeline, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выполняется около одного часа (без стеминга)**\n",
    "- Wall time: 1h 36min 37s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 10, 'tfidfvectorizer__max_df': 0.5, 'tfidfvectorizer__max_features': None, 'tfidfvectorizer__min_df': 1, 'tfidfvectorizer__ngram_range': (1, 2)}\n",
      "Wall time: 1h 36min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# grid.fit(df_train['BODY'], y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450428912951765"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(df_test['BODY'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.90      0.83      4812\n",
      "          1       0.66      0.43      0.52      2299\n",
      "\n",
      "avg / total       0.73      0.75      0.73      7111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid.predict(df_test['BODY'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4318  494]\n",
      " [1319  980]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4318, 494, 1319, 980)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, grid.predict(df_test['BODY'])))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(df_test['BODY'])).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выполняется**\n",
    "- Wall time: 5h 47min 9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 10, 'tfidfvectorizer__max_df': 0.5, 'tfidfvectorizer__max_features': None, 'tfidfvectorizer__min_df': 1, 'tfidfvectorizer__ngram_range': (1, 2), 'tfidfvectorizer__preprocessor': <function stemmer at 0x000000001E7B8E18>}\n",
      "Wall time: 5h 47min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 5h 47min 9s\n",
    "### grid2.fit(df_train['BODY'], y_train) \n",
    "print(grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446210097032766"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.score(df_test['BODY'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.89      0.83      4812\n",
      "          1       0.66      0.43      0.52      2299\n",
      "\n",
      "avg / total       0.73      0.74      0.73      7111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid2.predict(df_test['BODY'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4301  511]\n",
      " [1305  994]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4301, 511, 1305, 994)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, grid2.predict(df_test['BODY'])))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, grid2.predict(df_test['BODY'])).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры наилучшей модели и метрики классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GridSearchCV</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7450</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>not stemmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7446</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>with stemmer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GridSearchCV LogisticRegressionCV SGDClassifier         model\n",
       "0        0.7450               0.7533        0.7544   not stemmer\n",
       "1        0.7446                 none          none  with stemmer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametres_models = pd.DataFrame({'LogisticRegressionCV': [0.7533, 'none'],\n",
    "                                  'SGDClassifier': [0.7544, 'none'],\n",
    "                                  'GridSearchCV': [0.7450, 0.7446],\n",
    "                                  'model': ['not stemmer', 'with stemmer']})\n",
    "parametres_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7544649135142737\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.83      4812\n",
      "          1       0.69      0.43      0.53      2299\n",
      "\n",
      "avg / total       0.75      0.75      0.74      7111\n",
      "\n",
      "[[4378  434]\n",
      " [1312  987]]\n",
      "TN 4378\n",
      "FP 434\n",
      "FN 1312\n",
      "TP 987\n",
      "Wall time: 73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import  SGDClassifier\n",
    "sgd_logit = SGDClassifier(\n",
    "#     max_iter=(10 ** 6 / X_train.shape[0]), \n",
    "                          random_state=17, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "\n",
    "sgd_logit.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(y_test, sgd_logit.predict(X_test)))\n",
    "\n",
    "print(classification_report(y_test, sgd_logit.predict(X_test)))\n",
    "\n",
    "print(confusion_matrix(y_test, sgd_logit.predict(X_test)))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, sgd_logit.predict(X_test)).ravel()\n",
    "print('TN', tn)\n",
    "print('FP', fp)\n",
    "print('FN', fn)\n",
    "print('TP', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
